{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import dash_table\n",
    "import jupyter_dash\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional\n",
    "import random\n",
    "import numpy\n",
    "from dash_extensions import Download\n",
    "from dash_extensions.snippets import send_data_frame\n",
    "import base64\n",
    "import io\n",
    "import more_itertools\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(a):\n",
    "    if not a:\n",
    "        return False\n",
    "    try:\n",
    "        float(a)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Anomalies Class -----------------------\n",
    "@dataclass\n",
    "class Anomalies:\n",
    "    \n",
    "    # The dataframe\n",
    "    data: pd.DataFrame = None\n",
    "    \n",
    "    # indexes from previous simulation\n",
    "    siv_ps: List = field(default_factory=lambda: [])\n",
    "    ds_ps: List = field(default_factory=lambda: [])\n",
    "    sv_ps: List = field(default_factory=lambda: [])\n",
    "        \n",
    "    # Persistence min and max\n",
    "    persistence_min: int = 10\n",
    "    persistence_max: int = 10\n",
    "    \n",
    "    # Amplitude min and max\n",
    "    amplitude_min: float = 1.\n",
    "    amplitude_max: float = 1.\n",
    "    \n",
    "    # Minimum distance between anomalies\n",
    "    anomalies_dist_min: int = 5\n",
    "    \n",
    "    def save_data_with_anomalies(self, csv_name=\"anomalies.csv\"):\n",
    "        \"\"\" Method that saves the dataframe with anomalies \"\"\"\n",
    "        self.data.to_csv(path_or_buf=csv_name, index=False)\n",
    "            \n",
    "    def add_anomalies_name_and_value_columns(self):\n",
    "        \"\"\" Method that add anomalies columns name and values \"\"\"\n",
    "        self.data[\"anomaly_name\"] = \"\"\n",
    "        self.data[\"anomaly_value\"] = \"\"\n",
    "        \n",
    "    def choose_index(self, persistence=0):\n",
    "        \n",
    "        # Find all the allowed indexes\n",
    "        allowed_indexes = list(numpy.where(self.data[\"anomaly_value\"] == \"\")[0])\n",
    "\n",
    "        # Find the indexes that must be removed\n",
    "        indexes_to_remove = []\n",
    "        for ai in more_itertools.consecutive_groups(allowed_indexes):\n",
    "            ai_list = list(ai)\n",
    "            if ai_list:\n",
    "                    # Remove points before\n",
    "                    indexes_to_remove.extend(list(range(ai_list[0], ai_list[0] + self.anomalies_dist_min)))\n",
    "                    \n",
    "                    # Remove points after\n",
    "                    indexes_to_remove.extend(\n",
    "                        list(range(ai_list[-1], ai_list[-1] - self.anomalies_dist_min - persistence, -1))\n",
    "                    )\n",
    "        \n",
    "        # Remove the anomalies_dist_min and persistence points\n",
    "        allowed_indexes = list(set(allowed_indexes) - set(indexes_to_remove))\n",
    "        index = random.choice(allowed_indexes)\n",
    "        return index\n",
    "\n",
    "    \n",
    "    def spikes_in_values(\n",
    "        self, \n",
    "        amount='',\n",
    "        anomaly_name='',\n",
    "        persistence_min='', \n",
    "        persistence_max='',\n",
    "        amplitude_min='',\n",
    "        amplitude_max=''        \n",
    "    ):\n",
    "        \n",
    "        # ------- Remove the previous anomaly simulation --------\n",
    "        # get the indexes from the previous simulation\n",
    "        if self.siv_ps:\n",
    "            self.data.loc[self.siv_ps, \"anomaly_name\"] = \"\"\n",
    "            self.data.loc[self.siv_ps, \"anomaly_value\"] = \"\"\n",
    "        # -------------------------------------------------------    \n",
    "        \n",
    "        # Clean self.siv_ps for a new simulation\n",
    "        self.siv_ps = []\n",
    "        \n",
    "        # Check if the arguments are numeric\n",
    "        if is_number(amount):\n",
    "            for _ in range(int(amount)):\n",
    "                \n",
    "                amin = self.amplitude_min\n",
    "                amax = self.amplitude_max\n",
    "                \n",
    "                if is_number(amplitude_min):\n",
    "                    amin = float(amplitude_min)\n",
    "                \n",
    "                if is_number(amplitude_max):\n",
    "                    amax = float(amplitude_max)\n",
    "                \n",
    "                amplitude = random.uniform(min([amin, amax]), max([amin, amax]))              \n",
    "               \n",
    "                # Choose a proper index for the anomaly\n",
    "                index = self.choose_index()\n",
    "                value = self.data.at[index, settings[\"df_y_column\"]] + amplitude\n",
    "                self.data.at[index, \"anomaly_name\"] = anomaly_name\n",
    "                self.data.at[index, \"anomaly_value\"] = value\n",
    "                self.siv_ps.append(index)\n",
    "                \n",
    "    def stationary_values(\n",
    "        self, \n",
    "        amount='',\n",
    "        anomaly_name='',\n",
    "        persistence_min='', \n",
    "        persistence_max='',\n",
    "        amplitude_min='',\n",
    "        amplitude_max=''   \n",
    "    ):\n",
    "        \n",
    "        # ------- Remove the previous anomaly simulation --------\n",
    "        # get the indexes from the previous simulation\n",
    "        if self.sv_ps:\n",
    "            self.data.loc[self.sv_ps, \"anomaly_name\"] = \"\"\n",
    "            self.data.loc[self.sv_ps, \"anomaly_value\"] = \"\"\n",
    "        # -------------------------------------------------------    \n",
    "        \n",
    "        # Clean self.sv_ps for a new simulation\n",
    "        self.sv_ps = []\n",
    "        # Check if the arguments are numeric\n",
    "        if is_number(amount):\n",
    "            \n",
    "            # ---------- Persistence -------------------\n",
    "            pmin = self.persistence_min\n",
    "            pmax = self.persistence_max\n",
    "                \n",
    "            if is_number(persistence_min):\n",
    "                pmin = int(persistence_min)\n",
    "                \n",
    "            if is_number(persistence_max):\n",
    "                pmax = int(persistence_max)\n",
    "            # ------------------------------------------\n",
    "            \n",
    "            for _ in range(int(amount)):\n",
    "                \n",
    "                # Always a random persistence for each anomaly\n",
    "                persistence = random.randint(min([pmin, pmax]), max([pmin, pmax]))                                \n",
    "                                              \n",
    "                # Choose a proper index for the anomaly\n",
    "                index_s = self.choose_index(persistence=persistence)\n",
    "                index_e = index_s + persistence\n",
    "                \n",
    "                self.data.loc[index_s:index_e, \"anomaly_name\"] = anomaly_name\n",
    "                self.data.loc[index_s:index_e, \"anomaly_value\"] = self.data.at[index_s, settings[\"df_y_column\"]]\n",
    "                self.sv_ps.extend(list(range(index_s, index_e + 1)))\n",
    "                    \n",
    "    def sensor_displacement(\n",
    "        self, \n",
    "        amount='',\n",
    "        anomaly_name='',\n",
    "        persistence_min='', \n",
    "        persistence_max='',\n",
    "        amplitude_min='',\n",
    "        amplitude_max=''\n",
    "    ):\n",
    "        \n",
    "        # ------- Remove the previous anomaly simulation --------\n",
    "        # get the indexes from the previous simulation\n",
    "        if self.ds_ps:\n",
    "            self.data.loc[self.ds_ps, \"anomaly_name\"] = \"\"\n",
    "            self.data.loc[self.ds_ps, \"anomaly_value\"] = \"\"\n",
    "        # -------------------------------------------------------    \n",
    "        \n",
    "        # Clean self.ds_ps for a new simulation\n",
    "        self.ds_ps = []\n",
    "        # Check if the arguments are numeric\n",
    "        if amount.isnumeric():\n",
    "            \n",
    "            # ---------- Amplitude -------------------\n",
    "            amin = self.amplitude_min\n",
    "            amax = self.amplitude_max\n",
    "                \n",
    "            if is_number(amplitude_min):\n",
    "                amin = float(amplitude_min)\n",
    "                \n",
    "            if is_number(amplitude_max):\n",
    "                amax = float(amplitude_max)                \n",
    "            # ------------------------------------------\n",
    "            \n",
    "            # ---------- Persistence -------------------\n",
    "            pmin = self.persistence_min\n",
    "            pmax = self.persistence_max\n",
    "                \n",
    "            if is_number(persistence_min):\n",
    "                pmin = int(persistence_min)\n",
    "                \n",
    "            if is_number(persistence_max):\n",
    "                pmax = int(persistence_max)                \n",
    "            # ------------------------------------------\n",
    "            \n",
    "            for _ in range(int(amount)):\n",
    "                \n",
    "                # Always a random amplitude and persistence for each anomaly\n",
    "                amplitude = random.uniform(min([amin, amax]), max([amin, amax]))\n",
    "                persistence = random.randint(min([pmin, pmax]), max([pmin, pmax]))\n",
    "                                \n",
    "                # Choose a proper index for the anomaly\n",
    "                index_s = self.choose_index(persistence=persistence)\n",
    "                index_e = index_s + persistence\n",
    "                \n",
    "                self.data.loc[index_s:index_e, \"anomaly_name\"] = anomaly_name\n",
    "                self.data.loc[index_s:index_e, \"anomaly_value\"] = self.data.loc[index_s:index_e, settings[\"df_y_column\"]] + amplitude\n",
    "                self.ds_ps.extend(list(range(index_s, index_e + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_csv_content(csv_content=None, filename=None):\n",
    "    df = None\n",
    "    if csv_content:\n",
    "        content_type, content_string = csv_content.split(',')\n",
    "        decoded = base64.b64decode(content_string)\n",
    "        try:\n",
    "            if 'csv' in filename:\n",
    "                # Assume that the user uploaded a CSV file\n",
    "                df = pd.read_csv(\n",
    "                    io.StringIO(decoded.decode('utf-8'))\n",
    "                )\n",
    "            elif 'xls' in filename:\n",
    "                # Assume that the user uploaded an excel file\n",
    "                df = pd.read_excel(io.BytesIO(decoded))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- The project Settings --------------\n",
    "settings = {\n",
    "    \"df_x_column\": \"datetime\",\n",
    "    \"df_y_column\": \"measured\",\n",
    "    \"plot_settings\": {\n",
    "        \"x_label\": \"Date\",\n",
    "        \"y_label\": \"Water Level\",        \n",
    "        \"Original_Values\": {\n",
    "            \"color\": \"blue\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ The anomlies and their methods -------------------\n",
    "anomalies_methods = {\n",
    "    \"Spikes\": \"spikes_in_values\",\n",
    "    \"Stationary Values\": \"stationary_values\",\n",
    "    \"Sensor Displacement\": \"sensor_displacement\" \n",
    "}\n",
    "\n",
    "# Update the settings_plot from settings with the anomlies colors\n",
    "colors = [\"black\", \"red\", \"green\", \"black\"]\n",
    "for anomaly, index in zip(anomalies_methods, range(len(list(anomalies_methods.keys())))):\n",
    "    settings[\"plot_settings\"].update(\n",
    "        {\n",
    "            anomaly: {\n",
    "                \"color\": colors[index]\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- params --------------------------\n",
    "reference_parameters = {\n",
    "    \"load_csv_n_clicks\": 0,\n",
    "    \"injects_anomalies_n_clicks\": 0,\n",
    "    \"upload_dataframe_content\": \"\",\n",
    "    \"fig\": px.scatter(),\n",
    "    \"plots_first_index\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Start Anomalies Class and add the dataframe ---------------\n",
    "anomalies = Anomalies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- Tables ------------------------------\n",
    "anomalies_table = dash_table.DataTable(    \n",
    "    id='anomalies-table',\n",
    "    columns=(\n",
    "        [\n",
    "            {\n",
    "                'id': 'Anomaly', 'name': \"Anomaly\", 'editable': False\n",
    "            },\n",
    "            {\n",
    "                'id': 'Amount', 'name': \"Amount\", 'editable': True\n",
    "            },\n",
    "            {\n",
    "                'id': 'Amplitude (Min)', 'name': \"Amplitude (Min)\", 'editable': True\n",
    "            },\n",
    "            {\n",
    "                'id': 'Amplitude (Max)', 'name': \"Amplitude (Max)\", 'editable': True\n",
    "            },\n",
    "            {\n",
    "                'id': 'Persistence (Min)', 'name': \"Persistence (Min)\", 'editable': True\n",
    "            },\n",
    "            {\n",
    "                'id': 'Persistence (Max)', 'name': \"Persistence (Max)\", 'editable': True\n",
    "            }\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    data = [ \n",
    "        {\n",
    "            \"Anomaly\": anomaly_name,\n",
    "            \"Amount\": \"\",\n",
    "            \"Persistence (Min)\": \"\", \n",
    "            \"Persistence (Max)\": \"\",\n",
    "            \"Amplitude (Min)\": \"\",\n",
    "            \"Amplitude (Max)\": \"\"\n",
    "        }\n",
    "        for anomaly_name in anomalies_methods\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig_table = dash_table.DataTable(\n",
    "    \n",
    "    id='fig-table',\n",
    "    columns=(\n",
    "        [\n",
    "            {\n",
    "                'id': 'Date', 'name': \"Date\", 'editable': False\n",
    "            },\n",
    "            {\n",
    "                'id': 'Original Value', 'name': \"Original Value\", 'editable': False,\n",
    "            },\n",
    "            {\n",
    "                'id': 'Anomaly', 'name': \"Anomaly\", 'editable': False,\n",
    "            },\n",
    "            {\n",
    "                'id': 'Anomaly Value', 'name': \"Anomaly Value\", 'editable': False\n",
    "            }\n",
    "        ]\n",
    "    ),\n",
    "    data=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- App --------------------------\n",
    "app = jupyter_dash.JupyterDash(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- App layout -------------------\n",
    "app.layout = html.Div([\n",
    "    anomalies_table,\n",
    "    dcc.Upload(\n",
    "        id='upload-dataframe',\n",
    "        children=html.Div(\n",
    "            [\n",
    "                html.Button('Load csv', id='load-dataframe-button', n_clicks=0)\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    html.Button('Injects Anomalies', id='injects-anomalies-button', n_clicks=0),\n",
    "    html.Button('Download csv with Anomalies', id='download-dataframe-with-anomalies-button', n_clicks=0),\n",
    "    dcc.Graph(\n",
    "        id='anomalies-fig', \n",
    "        figure=reference_parameters['fig'],\n",
    "    ),\n",
    "    fig_table,\n",
    "    Download(id=\"download-anomalies-csv\"),    \n",
    "    html.Div(id='output-data-upload')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- Select Data display table Callback -----------------------\n",
    "@app.callback(\n",
    "    Output('fig-table', 'data'),\n",
    "    [\n",
    "        Input('anomalies-fig', 'selectedData')        \n",
    "    ]\n",
    ")\n",
    "def select_data_display_table(selectedData):\n",
    "    data = []\n",
    "    if selectedData:\n",
    "        # --------------\n",
    "        # TODO: Since two plots intersect when the rectangle or lasso selector are used\n",
    "        # two (2) equal points of data are shown in the table to fix just\n",
    "        # check if Date are in the data list because there is no way of two points\n",
    "        # have the same date\n",
    "        # --------------\n",
    "        data = []\n",
    "        for point in selectedData['points']:                \n",
    "            pi = point['pointIndex']\n",
    "            cn =  point['curveNumber']\n",
    "            correct_index = pi + reference_parameters[\"plots_first_index\"][cn]\n",
    "            data.append(\n",
    "                {\n",
    "                    \"Date\":anomalies.data.at[correct_index, settings[\"df_x_column\"]],\n",
    "                    \"Original Value\": anomalies.data.at[correct_index, settings[\"df_y_column\"]],\n",
    "                    \"Anomaly\": anomalies.data.at[correct_index, \"anomaly_name\"], \n",
    "                    \"Anomaly Value\": anomalies.data.at[correct_index, \"anomaly_value\"]\n",
    "                }\n",
    "            )\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- Download Csv with Anomalies  Callback -----------------------\n",
    "@app.callback(\n",
    "    Output(\"download-anomalies-csv\", \"data\"),\n",
    "    [\n",
    "        Input('download-dataframe-with-anomalies-button', 'n_clicks')\n",
    "    ]\n",
    ")\n",
    "def download_dataframe_with_anomalies(n_clicks):\n",
    "    if n_clicks:\n",
    "        return send_data_frame(anomalies.data.to_csv, filename=\"anomalies.csv\")\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- Load CSV and Injects Anomalies Callback ----------------------\n",
    "@app.callback(\n",
    "    Output('anomalies-fig', 'figure'),\n",
    "    [\n",
    "        Input('load-dataframe-button', 'n_clicks'),\n",
    "        Input('injects-anomalies-button', 'n_clicks'),\n",
    "        Input('anomalies-table', 'data'),\n",
    "        Input('upload-dataframe', 'contents')\n",
    "    ],\n",
    "    [\n",
    "        State('upload-dataframe', 'filename'),\n",
    "        State('upload-dataframe', 'last_modified')\n",
    "    ]   \n",
    ")\n",
    "def load_csv_and_injects_anomalies(\n",
    "    load_csv_n_clicks,\n",
    "    injects_anomalies_n_clicks,\n",
    "    anomalies_table_data,\n",
    "    upload_dataframe_content,\n",
    "    upload_dataframe_filename,\n",
    "    upload_dataframe_last_modified\n",
    "):\n",
    "      \n",
    "    # ----------------------------- LOAD THE CSV ------------------------------------\n",
    "    if load_csv_n_clicks != reference_parameters[\"load_csv_n_clicks\"]:\n",
    "        if upload_dataframe_content:\n",
    "            if upload_dataframe_content != reference_parameters[\"upload_dataframe_content\"]:\n",
    "            \n",
    "                # Load and decode the csv\n",
    "                df = decode_csv_content(csv_content=upload_dataframe_content, filename=upload_dataframe_filename)\n",
    "                anomalies.data = df.copy()\n",
    "                anomalies.add_anomalies_name_and_value_columns()\n",
    "\n",
    "                # Create a figure for the csv\n",
    "                fig = px.scatter(df, x=settings[\"df_x_column\"], y=settings[\"df_y_column\"], render_mode='webgl')\n",
    "                fig.data[0].update(mode='markers+lines', marker={'size': 1, 'color': 'blue'})\n",
    "                fig.update_layout(\n",
    "                    clickmode='event+select',\n",
    "                    yaxis={\"title\": settings[\"plot_settings\"][\"y_label\"]},\n",
    "                    xaxis={\"title\": settings[\"plot_settings\"][\"x_label\"]}\n",
    "                )\n",
    "                \n",
    "                \n",
    "                # Saving the first index of the plot because each plot\n",
    "                # will restart with index = 0\n",
    "                reference_parameters[\"plots_first_index\"][0] = 0\n",
    "                \n",
    "                # Update Reference Parameters    \n",
    "                reference_parameters[\"load_csv_n_clicks\"] = load_csv_n_clicks\n",
    "                reference_parameters[\"upload_dataframe_content\"] = upload_dataframe_content\n",
    "                reference_parameters[\"fig\"] = fig\n",
    "    \n",
    "    # ------------------------ INJECTS ANOMALIES -----------------------------------------\n",
    "    if injects_anomalies_n_clicks != reference_parameters[\"injects_anomalies_n_clicks\"]:\n",
    "        if upload_dataframe_content:\n",
    "            \n",
    "                # Injects anomalies in the anomlies.data and return the \n",
    "                for anomaly in anomalies_table_data:\n",
    "                    \n",
    "                    getattr(anomalies, anomalies_methods[anomaly[\"Anomaly\"]])(\n",
    "                        amount=anomaly[\"Amount\"],\n",
    "                        anomaly_name=anomaly[\"Anomaly\"],\n",
    "                        persistence_min=anomaly[\"Persistence (Min)\"],\n",
    "                        persistence_max=anomaly[\"Persistence (Max)\"],\n",
    "                        amplitude_min=anomaly[\"Amplitude (Min)\"],\n",
    "                        amplitude_max=anomaly[\"Amplitude (Max)\"]\n",
    "                    )\n",
    "                    \n",
    "                # ------------------ Break the fig in various Subplots ------------------------------\n",
    "                # Get the indexes for original values (without anomalies) and indexes with anomalies\n",
    "                original_indexes = numpy.where(anomalies.data[\"anomaly_value\"] == \"\")[0]\n",
    "                anomalies_indexes = numpy.where(anomalies.data[\"anomaly_value\"] != \"\")[0]\n",
    "                \n",
    "                # The indexes with each plot\n",
    "                plots_indexes = []\n",
    "                \n",
    "                # Break the indexes for each plot with original values\n",
    "                for plot in more_itertools.consecutive_groups(original_indexes):\n",
    "                    plots_indexes.append(list(plot))\n",
    "                \n",
    "                # Break the indexes for each plot with anomalies\n",
    "                for plot in more_itertools.consecutive_groups(anomalies_indexes):\n",
    "                    plots_indexes.append(list(plot))\n",
    "                                \n",
    "                # Define a fig\n",
    "                # render_mode MUST BE webgl                \n",
    "                fig = px.scatter(render_mode='webgl')\n",
    "                \n",
    "                # Create a subplot for each plot_indexes\n",
    "                for plot_indexes, plot_id in zip(plots_indexes, range(len(plots_indexes))):\n",
    "                    \n",
    "                    # Add the subplots with \n",
    "                    # Get the name of the anomaly\n",
    "                    anomaly_name = anomalies.data.loc[plot_indexes[0], \"anomaly_name\"]\n",
    "                    y_var = \"anomaly_value\"\n",
    "                    if not anomaly_name:\n",
    "                        anomaly_name = \"Original_Values\"\n",
    "                        y_var = settings[\"df_y_column\"]\n",
    "                    \n",
    "                    # Get x and y\n",
    "                    plot_x = anomalies.data.loc[plot_indexes, settings[\"df_x_column\"]].tolist()\n",
    "                    plot_y = anomalies.data.loc[plot_indexes, y_var].tolist()\n",
    "                    \n",
    "                    \n",
    "                    # Saving the first index of the plot because each plot\n",
    "                    # will restart with index = 0\n",
    "                    reference_parameters[\"plots_first_index\"][plot_id] = plot_indexes[0]\n",
    "                    \n",
    "                                                       \n",
    "                    # To connect the plots add 1 point before the first point of the plot\n",
    "                    # and 1 point after the last point of the plot\n",
    "                    if anomaly_name != \"Original_Values\":\n",
    "                        \n",
    "                        # 1 point before the first point of the plot\n",
    "                        if plot_indexes[0] > 0:\n",
    "                            plot_x.insert(0, anomalies.data.at[plot_indexes[0] - 1, settings[\"df_x_column\"]])\n",
    "                            plot_y.insert(0, anomalies.data.at[plot_indexes[0] - 1, settings[\"df_y_column\"]])\n",
    "                            \n",
    "                            # Fix in case of anomaly\n",
    "                            reference_parameters[\"plots_first_index\"][plot_id] = plot_indexes[0] - 1\n",
    "                                                                                \n",
    "                        # 1 point after the last point of the plot\n",
    "                        if plot_indexes[-1] < anomalies.data.shape[0]:\n",
    "                            plot_x.append(anomalies.data.at[plot_indexes[-1] + 1, settings[\"df_x_column\"]])\n",
    "                            plot_y.append(anomalies.data.at[plot_indexes[-1] + 1, settings[\"df_y_column\"]])\n",
    "                        \n",
    "                    fig.add_traces(\n",
    "                        # ScatterGL for performance\n",
    "                        go.Scattergl(  \n",
    "                            x=plot_x, y=plot_y,\n",
    "                            mode='markers+lines',\n",
    "                            marker={'size': 1, 'color': settings[\"plot_settings\"][anomaly_name][\"color\"]},\n",
    "                            line={'color': settings[\"plot_settings\"][anomaly_name][\"color\"]}                            \n",
    "                        )                        \n",
    "                    )\n",
    "                fig.update_layout(\n",
    "                    clickmode='event+select',\n",
    "                    showlegend=False,\n",
    "                    yaxis={\"title\": settings[\"plot_settings\"][\"y_label\"]},\n",
    "                    xaxis={\"title\": settings[\"plot_settings\"][\"x_label\"]}\n",
    "                )\n",
    "                # -----------------------------------------------------------------------\n",
    "                \n",
    "                # Update Reference Parameters    \n",
    "                reference_parameters[\"injects_anomalies_n_clicks\"] = injects_anomalies_n_clicks\n",
    "                reference_parameters[\"upload_dataframe_content\"] = upload_dataframe_content\n",
    "                reference_parameters[\"fig\"] = fig\n",
    "                \n",
    "    return reference_parameters[\"fig\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "# --------------------- MAIN --------------------\n",
    "if __name__ == '__main__':\n",
    "#     app.run_server(mode=\"inline\")\n",
    "    app.run_server()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
